{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a06143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "Done: Load vocabulary.\n",
      "Done: loading pairs: ./dataset/train_100k_pairs.jsonl\n",
      "Done: loading pairs: ./dataset/valid_pairs.jsonl\n",
      "Done: loading pairs: ./dataset/test_pairs.jsonl\n",
      "Demo initialized with strategy: beam\n",
      "Done: Init model with ./saved_vocab_embedding/src_embedding.pkl and ./saved_vocab_embedding/tgt_embedding.pkl.\n",
      "Done: init saver.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "验证: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集 Loss: 9.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练:   2%|▏         | 6/391 [00:02<03:04,  2.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m验证集 Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     14\u001b[0m strat\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/home/NMT/exp_frame.py:162\u001b[0m, in \u001b[0;36mExp_frame.train\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    161\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 162\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(valid_loader,criterion)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/home/NMT/rnn_frame.py:152\u001b[0m, in \u001b[0;36mRNN_frame.train_epoch\u001b[0;34m(self, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m    149\u001b[0m tgt_output \u001b[38;5;241m=\u001b[39m tgt_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)           \u001b[38;5;66;03m# (tgt_len * batch_size,)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, tgt_output)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[1;32m    155\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rnn_frame import RNN_frame\n",
    "from pprint import pprint\n",
    "from transformer_frame import Transformer_frame\n",
    "#e = Transformer_frame()\n",
    "e = RNN_frame()\n",
    "#e.load_model(save=False)\n",
    "#e.test([(\"我 爱 自然 语言 处理 。\",\"i love natural language processing .\"),\n",
    "#        (\"今天 天气 很 好 。\",\"the weather is nice today .\")])\n",
    "e.init_model(save=True)\n",
    "loss = e.evaluate()\n",
    "print(f'验证集 Loss: {loss:.3f}')\n",
    "e.train(n_epochs=10)\n",
    "import time\n",
    "strat=time.time()\n",
    "e.test(e.train_pairs[0:10],show=False,strategy='beam')\n",
    "end=time.time()\n",
    "mins, secs = divmod(end - strat, 60)\n",
    "#print(f'Test 用时: {mins}m {secs:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76de0059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo initialized with strategy: beam\n",
      "\n",
      "===翻译示例 ===\n",
      "\n",
      "0. 1929年 还是 1989年 ?\n",
      "参考: 1929 or 1989 ?\n",
      "模型: , , , <eos>\n",
      "\n",
      "1. 巴黎 - 随着 经济危机 不断 加深 和 蔓延 ， 整个 世界 一直 在 寻找 历史 上 的 类似 事件 希望 有助于 我们 了解 目前 正在 发生 的 情况 。\n",
      "参考: paris – as the economic crisis deepens and widens , the world has been searching for historical analogies to help us understand what has been happening .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , the the the the the . <eos>\n",
      "\n",
      "2. 一开始 ， 很多 人 把 这次 危机 比作 1982年 或 1973年 所 发生 的 情况 ， 这样 得 类比 是 令人 宽心 的 ， 因为 这 两段 时期 意味着 典型 的 周期性 衰退 。\n",
      "参考: at the start of the crisis , many people likened it to 1982 or 1973 , which was reassuring , because both dates refer to classical cyclical downturns .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , , , the the the . <eos>\n",
      "\n",
      "3. 如今 人们 的 心情 却 是 沉重 多 了 ， 许多 人 开始 把 这次 危机 与 1929年 和 1931年 相比 ， 即使 一些 国家 政府 的 表现 仍然 似乎 把 视 目前 的 情况 为 是 典型 的 而 看见 的 衰退 。\n",
      "参考: today , the mood is much grimmer , with references to 1929 and 1931 beginning to abound , even if some governments continue to behave as if the crisis was more classical than exceptional .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , the the the . <eos>\n",
      "\n",
      "4. 目前 的 趋势 是 ， 要么 是 过度 的 克制 （ 欧洲 ） ， 要么 是 努力 的 扩展 （ 美国 ） 。\n",
      "参考: the tendency is either excessive restraint ( europe ) or a diffusion of the effort ( the united states ) .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , the the <eos>\n",
      "\n",
      "5. 欧洲 在 避免 债务 和 捍卫 欧元 的 名义 下 正 变得 谨慎 ， 而 美国 已经 在 许多 方面 行动 起来 ， 以 利用 这 一 理想 的 时机 来 实行 急需 的 结构性 改革 。\n",
      "参考: europe is being cautious in the name of avoiding debt and defending the euro , whereas the us has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , the the . <eos>\n",
      "\n",
      "6. 然而 ， 作为 地域 战略 学 家 ， 无论 是 从 政治 意义 还是 从 经济 意义 上 ， 让 我 自然 想到 的 年份 是 1989年 。\n",
      "参考: for geo-strategists , however , the year that naturally comes to mind , in both politics and economics , is 1989 .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , the the . <eos>\n",
      "\n",
      "7. 当然 ， 雷曼兄弟公司 的 倒闭 和 柏林 墙 的 倒塌 没有 任何 关系 。\n",
      "参考: of course , the fall of the house of lehman brothers has nothing to do with the fall of the berlin wall .\n",
      "模型: , , , , , , , , , , , , , , , the the <eos>\n",
      "\n",
      "8. 事实上 ， 从 表面 上 看 ， 两者 似乎 是 完全 是 相反 的 ： 一个 是 象征 着 压抑 和 人为 分裂 的 柏林 墙 的 倒塌 ， 而 另一个 是 看似 坚不可摧 的 并 令人 安心 的 金融 资本主义 机构 的 倒塌 。\n",
      "参考: indeed , on the surface it seems to be its perfect antithesis : the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , the the . <eos>\n",
      "\n",
      "9. 然而 ， 和 1989年 一样 ， 2008-2009年 很 可能 也 能 被 视为 一个 划时代 的 改变 ， 其 带来 的 发人深省 的 后果 将 在 几十年 后 仍 能 让 我们 感受 得到 。\n",
      "参考: yet 2008-2009 , like 1989 , may very well correspond to an epochal change , whose unfolding consequences will be felt for decades .\n",
      "模型: , , , , , , , , , , , , , , , , , , , , , , , , , , , , the the . <eos>\n",
      "====================\n",
      "\n",
      "{'correct': [39, 4, 0, 0],\n",
      " 'exp_brevity_penalty': 1.0,\n",
      " 'hyps_len': 264,\n",
      " 'linear_brevity_penalty': 1.0,\n",
      " 'p_smooth': [14.772727272727273,\n",
      "              1.5748031496062993,\n",
      "              0.20491803278688525,\n",
      "              0.10683760683760683],\n",
      " 'percent': [14.772727272727273, 1.574803149606299, 0.0, 0.0],\n",
      " 'ppt_bleu_score': 0.0,\n",
      " 'ref_len': 260,\n",
      " 'sacrebleu_score': 0.8447881650319351,\n",
      " 'total': [264, 254, 244, 234]}\n"
     ]
    }
   ],
   "source": [
    "e.test(e.train_pairs[0:10],show=True,strategy='beam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
